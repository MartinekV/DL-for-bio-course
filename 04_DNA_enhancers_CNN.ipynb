{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAy48y8dfWP3MEe8/aZrn2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartinekV/DL-for-bio-course/blob/master/04_DNA_enhancers_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feeding sequence into a NN"
      ],
      "metadata": {
        "id": "98lClS2BuPnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Activate gpu\n",
        "# Runtime -> Change runtime type -> T4 GPU\n",
        "\n",
        "example_seq = 'ACCCTGCCAACACGGGACTTTAC'\n",
        "vocab = {'A':0,'C':1,'T':2,'G':3}\n",
        "numericalized = [vocab[c] for c in example_seq]\n",
        "\n",
        "print(numericalized)"
      ],
      "metadata": {
        "id": "JVhdqcmWq67s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "numericalized_tensor = torch.tensor(numericalized)\n",
        "ohe_seq = torch.nn.functional.one_hot(numericalized_tensor, num_classes=4).float()\n",
        "\n",
        "print(ohe_seq)\n",
        "print(ohe_seq.shape)"
      ],
      "metadata": {
        "id": "WL9PgorSC_hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_seq = ohe_seq.flatten()\n",
        "\n",
        "print(flattened_seq)\n",
        "print(flattened_seq.shape)"
      ],
      "metadata": {
        "id": "-z8UY7eNv6lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Linear(in_features=92, out_features=1, bias=True)\n",
        "model(flattened_seq)"
      ],
      "metadata": {
        "id": "0Q-yycplulAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleClassifier(nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Linear(input_size, 1),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "model = SimpleClassifier(input_size=92) # Quiz - how many parameters do we have?\n",
        "model(flattened_seq)"
      ],
      "metadata": {
        "id": "xZAKiG47sptL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real dataset"
      ],
      "metadata": {
        "id": "uHrfonkHzEf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data exploration"
      ],
      "metadata": {
        "id": "jv0EP5Uvvm0e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH_yVOQWUR8t"
      },
      "outputs": [],
      "source": [
        "!pip install -q genomic-benchmarks\n",
        "!pip install torchmetrics -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import HumanNontataPromoters\n",
        "import pandas as pd\n",
        "\n",
        "train_dset =  HumanNontataPromoters('train')\n",
        "train_df = pd.DataFrame(data=[{'x':x,'y':y} for x,y in train_dset])\n",
        "\n",
        "train_df"
      ],
      "metadata": {
        "id": "U9kkvSDlX4YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length_counts = train_df['x'].apply(len).value_counts()\n",
        "print(\"Length counts of the DNA sequences:\")\n",
        "print(length_counts)\n",
        "\n",
        "label_counts = train_df['y'].value_counts()\n",
        "print(\"\\nCounts of the labels y:\")\n",
        "print(label_counts)"
      ],
      "metadata": {
        "id": "dRd1d3Liziss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class FlattenedDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "      self.df = df\n",
        "      self.vocab = {'N':0,'A':1,'C':2,'T':3,'G':4}\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      sequence, label = self.df.iloc[idx]\n",
        "\n",
        "      numericalized = [self.vocab[c] for c in sequence]\n",
        "      numericalized_tensor = torch.tensor(numericalized)\n",
        "      ohe_seq = torch.nn.functional.one_hot(\n",
        "          numericalized_tensor,\n",
        "          num_classes=len(self.vocab.keys())\n",
        "      )\n",
        "\n",
        "      x = ohe_seq.flatten().float()\n",
        "      y = torch.tensor([label]).float()\n",
        "\n",
        "      return x, y\n",
        "\n",
        "dset = FlattenedDataset(train_df)\n",
        "\n",
        "sample_x, sample_y = dset[0]\n",
        "\n",
        "print(sample_x, sample_y)\n",
        "print(sample_x.shape, sample_y.shape)"
      ],
      "metadata": {
        "id": "kvvi0Z1-4WA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleClassifier(input_size=1255)\n",
        "\n",
        "x,y = dset[0]\n",
        "model(x)"
      ],
      "metadata": {
        "id": "e2CkCIGQazTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "fG476dHVwlIK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x_batch, y_batch in train_loader:\n",
        "  print(x_batch)\n",
        "  print(y_batch)\n",
        "  print(x_batch.shape, y_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "ZcP3vPtszfMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(x_batch)"
      ],
      "metadata": {
        "id": "6vBaO9Pd6SpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "VbM9Go_v-Ur3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleClassifier(nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Linear(input_size, 1),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "v3EILajCI7Lt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataset, batch_size=32, lr=1e-3, epochs=3):\n",
        "  train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  loss_function = nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for batch_x, batch_y in train_loader:\n",
        "      outputs = model(batch_x)\n",
        "      loss = loss_function(outputs, batch_y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    print(loss.item())"
      ],
      "metadata": {
        "id": "ECh8hwm5x4tO"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dset = FlattenedDataset(train_df)\n",
        "model = SimpleClassifier(input_size=1255)\n",
        "train(model, train_dset)"
      ],
      "metadata": {
        "id": "SCisbzgFy7rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "bK0dw2UXGvt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "def evaluate(model, dataset):\n",
        "  loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "  accuracy_function = Accuracy(task='binary')\n",
        "\n",
        "  model.eval() #Turn off training-only layers\n",
        "  all_predictions = []\n",
        "  all_labels = []\n",
        "  with torch.no_grad(): #Dont track gradients\n",
        "    for batch_x,batch_y in tqdm(loader):\n",
        "      output = model(batch_x)\n",
        "      all_predictions.append(output)\n",
        "      all_labels.append(batch_y)\n",
        "\n",
        "  print('Accuracy:', accuracy_function(torch.cat(all_predictions), torch.cat(all_labels)).item())"
      ],
      "metadata": {
        "id": "UhhiegkY1oEQ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, train_dset)"
      ],
      "metadata": {
        "id": "ls_mdP8J8Q4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(data=[{'x':x,'y':y} for x,y in HumanNontataPromoters('test')])\n",
        "test_dset = FlattenedDataset(test_df)\n",
        "\n",
        "evaluate(model, test_dset)"
      ],
      "metadata": {
        "id": "0sf5KE_UHBrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-layer perceptron (MLP)"
      ],
      "metadata": {
        "id": "T4PvSX23Y_Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    #TODO\n",
        "    pass\n",
        "\n",
        "  def forward(self,x):\n",
        "    #TODO\n",
        "    pass\n",
        "\n",
        "# Test the MLP\n",
        "mlp_model = MLP(input_size=1255, hidden_size = 100, num_classes=1)\n",
        "sample_input = torch.rand(32,1255)\n",
        "mlp_model(sample_input).size()"
      ],
      "metadata": {
        "id": "NmdcObQsKY30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(mlp_model, train_dset)"
      ],
      "metadata": {
        "id": "flSbU3lP9pjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(mlp_model, train_dset)\n",
        "evaluate(mlp_model, test_dset)"
      ],
      "metadata": {
        "id": "d0GaGsf7-7OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network (CNN)"
      ],
      "metadata": {
        "id": "08j8lsIzZFEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, in_channels, num_classes):\n",
        "    super().__init__()\n",
        "    #TODO\n",
        "    pass\n",
        "\n",
        "  def forward(self,x):\n",
        "    #TODO\n",
        "    pass\n",
        "\n",
        "# Test the CNN\n",
        "cnn_model = CNN(in_channels=5, num_classes=1)\n",
        "sample_input = torch.rand(32,5,251)\n",
        "cnn_model(sample_input).size()"
      ],
      "metadata": {
        "id": "8B02rPUbLSvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "      self.df = df\n",
        "      self.vocab = {'N':0,'A':1,'C':2,'T':3,'G':4}\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      #TODO change pre-processing to fit CNN\n",
        "\n",
        "      sequence, label = self.df.iloc[idx]\n",
        "\n",
        "      numericalized = [self.vocab[c] for c in sequence]\n",
        "      numericalized_tensor = torch.tensor(numericalized)\n",
        "      ohe_seq = torch.nn.functional.one_hot(\n",
        "          numericalized_tensor,\n",
        "          num_classes=len(self.vocab.keys())\n",
        "      )\n",
        "\n",
        "      x = ohe_seq.flatten().float()\n",
        "      y = torch.tensor([label]).float()\n",
        "\n",
        "      return x, y\n",
        "\n",
        "train_dset = CNNDataset(train_df)\n",
        "sample_x, sample_y = train_dset[0]\n",
        "print(sample_x.shape)\n",
        "print(sample_y.shape)"
      ],
      "metadata": {
        "id": "IHdC6pqsAV3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(cnn_model, train_dset)"
      ],
      "metadata": {
        "id": "xGgemo9LBi_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dset = CNNDataset(test_df)\n",
        "\n",
        "evaluate(cnn_model, train_dset)\n",
        "evaluate(cnn_model, test_dset)"
      ],
      "metadata": {
        "id": "BXU4bdkbCdxf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}