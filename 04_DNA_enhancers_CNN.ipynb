{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8Cnx3-za46pL"
      ],
      "authorship_tag": "ABX9TyPo6IGg0wb9/psb4ts06n7T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartinekV/DL-for-bio-course/blob/master/04_DNA_enhancers_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feeding sequence into a NN"
      ],
      "metadata": {
        "id": "98lClS2BuPnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Activate gpu\n",
        "# Runtime -> Change runtime type -> T4 GPU\n",
        "\n",
        "example_seq = 'ACCCTGCCAACACGGGACTTTAC'\n",
        "vocab = {\n",
        "    'A':0,\n",
        "    'C':1,\n",
        "    'T':2,\n",
        "    'G':3\n",
        "}\n",
        "numericalized = [vocab[c] for c in example_seq]\n",
        "\n",
        "print(numericalized)"
      ],
      "metadata": {
        "id": "JVhdqcmWq67s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "numericalized_tensor = torch.tensor(numericalized)\n",
        "ohe_seq = torch.nn.functional.one_hot(numericalized_tensor, num_classes=4).float()\n",
        "\n",
        "print(ohe_seq)\n",
        "print(ohe_seq.shape)"
      ],
      "metadata": {
        "id": "WL9PgorSC_hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_seq = ohe_seq.flatten()\n",
        "\n",
        "print(flattened_seq)\n",
        "print(flattened_seq.shape)"
      ],
      "metadata": {
        "id": "-z8UY7eNv6lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Linear(in_features=92, out_features=1, bias=True)\n",
        "model(flattened_seq)"
      ],
      "metadata": {
        "id": "0Q-yycplulAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleClassifier(nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Linear(input_size, 1),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "model = SimpleClassifier(input_size=92) # Quiz - how many parameters do we have?\n",
        "model(flattened_seq)"
      ],
      "metadata": {
        "id": "xZAKiG47sptL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real dataset"
      ],
      "metadata": {
        "id": "uHrfonkHzEf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data exploration"
      ],
      "metadata": {
        "id": "jv0EP5Uvvm0e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aH_yVOQWUR8t"
      },
      "outputs": [],
      "source": [
        "!pip install -q genomic-benchmarks\n",
        "!pip install torchmetrics -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import HumanNontataPromoters\n",
        "import pandas as pd\n",
        "\n",
        "train_dset =  HumanNontataPromoters('train')\n",
        "train_df = pd.DataFrame(data=[{'x':x,'y':y} for x,y in train_dset])\n",
        "\n",
        "train_df"
      ],
      "metadata": {
        "id": "U9kkvSDlX4YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length_counts = train_df['x'].apply(len).value_counts()\n",
        "print(\"Length counts of the DNA sequences:\")\n",
        "print(length_counts)\n",
        "\n",
        "label_counts = train_df['y'].value_counts()\n",
        "print(\"\\nCounts of the labels y:\")\n",
        "print(label_counts)"
      ],
      "metadata": {
        "id": "dRd1d3Liziss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class FlattenedDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "      self.df = df\n",
        "      self.vocab = {\n",
        "          'N':0,\n",
        "          'A':1,\n",
        "          'C':2,\n",
        "          'T':3,\n",
        "          'G':4\n",
        "      }\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      sequence, label = self.df.iloc[idx]\n",
        "\n",
        "      numericalized = [self.vocab[c] for c in sequence]\n",
        "      numericalized_tensor = torch.tensor(numericalized)\n",
        "      ohe_seq = torch.nn.functional.one_hot(\n",
        "          numericalized_tensor,\n",
        "          num_classes=len(self.vocab.keys())\n",
        "      )\n",
        "\n",
        "      x = ohe_seq.flatten().float()\n",
        "      y = torch.tensor([label]).float()\n",
        "\n",
        "      return x, y\n",
        "\n",
        "dset = FlattenedDataset(train_df)\n",
        "\n",
        "sample_x, sample_y = dset[0]\n",
        "\n",
        "print(sample_x, sample_y)\n",
        "print(sample_x.shape, sample_y.shape)"
      ],
      "metadata": {
        "id": "kvvi0Z1-4WA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleClassifier(input_size=1255)\n",
        "\n",
        "x,y = dset[0]\n",
        "model(x)"
      ],
      "metadata": {
        "id": "e2CkCIGQazTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "fG476dHVwlIK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x_batch, y_batch in train_loader:\n",
        "  print(x_batch)\n",
        "  print(y_batch)\n",
        "  print(x_batch.shape, y_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "ZcP3vPtszfMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(x_batch)"
      ],
      "metadata": {
        "id": "6vBaO9Pd6SpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "VbM9Go_v-Ur3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleClassifier(nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Linear(input_size, 1),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "v3EILajCI7Lt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Training using classification loss and Adam optimizer\n",
        "def train(model, dataset, batch_size=32, lr=1e-3, epochs=3, gpu=True):\n",
        "  if(gpu):\n",
        "    model.cuda()\n",
        "\n",
        "  train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  loss_function = nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    batch_losses = []\n",
        "    for batch_x, batch_y in train_loader:\n",
        "      if(gpu):\n",
        "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
        "      outputs = model(batch_x)\n",
        "      loss = loss_function(outputs, batch_y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      batch_losses.append(loss.item())\n",
        "\n",
        "    print('Mean loss', np.mean(batch_losses))"
      ],
      "metadata": {
        "id": "ECh8hwm5x4tO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dset = FlattenedDataset(train_df)\n",
        "model = SimpleClassifier(input_size=1255)\n",
        "train(model, train_dset, epochs=10)"
      ],
      "metadata": {
        "id": "SCisbzgFy7rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "bK0dw2UXGvt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "def evaluate(model, dataset, gpu=True):\n",
        "  accuracy_function = Accuracy(task='binary')\n",
        "\n",
        "  if(gpu):\n",
        "    model.cuda()\n",
        "    accuracy_function.cuda()\n",
        "\n",
        "  loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "  model.eval() #Turn off training-only layers\n",
        "  all_predictions = []\n",
        "  all_labels = []\n",
        "  with torch.no_grad(): #Dont track gradients\n",
        "    for batch_x,batch_y in tqdm(loader):\n",
        "      if(gpu):\n",
        "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
        "\n",
        "      output = model(batch_x)\n",
        "      all_predictions.append(output)\n",
        "      all_labels.append(batch_y)\n",
        "\n",
        "  print('Accuracy:', accuracy_function(torch.cat(all_predictions), torch.cat(all_labels)).item())"
      ],
      "metadata": {
        "id": "UhhiegkY1oEQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, train_dset)"
      ],
      "metadata": {
        "id": "ls_mdP8J8Q4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621fe890-dae6-41fe-e3cd-d0007bf8d017"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 847/847 [00:07<00:00, 110.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8309776186943054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(data=[{'x':x,'y':y} for x,y in HumanNontataPromoters('test')])\n",
        "test_dset = FlattenedDataset(test_df)\n",
        "\n",
        "evaluate(model, test_dset)"
      ],
      "metadata": {
        "id": "0sf5KE_UHBrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3589ec34-a824-4151-8834-ea853924a52c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 283/283 [00:03<00:00, 85.16it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8149213790893555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-layer perceptron (MLP)"
      ],
      "metadata": {
        "id": "T4PvSX23Y_Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    #TODO\n",
        "    pass\n",
        "\n",
        "  def forward(self,x):\n",
        "    #TODO\n",
        "    pass\n",
        "\n",
        "# Test the MLP\n",
        "mlp_model = MLP(input_size=1255, hidden_size = 100)\n",
        "sample_input = torch.rand(32,1255)\n",
        "mlp_model(sample_input).size()"
      ],
      "metadata": {
        "id": "NmdcObQsKY30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(mlp_model, train_dset, epochs=10)"
      ],
      "metadata": {
        "id": "flSbU3lP9pjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(mlp_model, train_dset)\n",
        "evaluate(mlp_model, test_dset)"
      ],
      "metadata": {
        "id": "d0GaGsf7-7OK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb772e0-6175-4211-d20e-be991d4b8c3b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 847/847 [00:06<00:00, 128.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9987083673477173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 283/283 [00:02<00:00, 100.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8308612108230591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network (CNN)"
      ],
      "metadata": {
        "id": "08j8lsIzZFEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super().__init__()\n",
        "    #TODO\n",
        "    pass\n",
        "\n",
        "  def forward(self,x):\n",
        "    #TODO\n",
        "    pass\n",
        "\n",
        "# Test the CNN\n",
        "cnn_model = CNN(in_channels=5)\n",
        "sample_input = torch.rand(32,5,251)\n",
        "cnn_model(sample_input).size()"
      ],
      "metadata": {
        "id": "8B02rPUbLSvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change pre-processing to fit CNN\n",
        "\n",
        "class CNNDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "      self.df = df\n",
        "      self.vocab = {\n",
        "          'N':0,\n",
        "          'A':1,\n",
        "          'C':2,\n",
        "          'T':3,\n",
        "          'G':4\n",
        "      }\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      sequence, label = self.df.iloc[idx]\n",
        "\n",
        "      numericalized = [self.vocab[c] for c in sequence]\n",
        "      numericalized_tensor = torch.tensor(numericalized)\n",
        "      ohe_seq = torch.nn.functional.one_hot(\n",
        "          numericalized_tensor,\n",
        "          num_classes=len(self.vocab.keys())\n",
        "      )\n",
        "\n",
        "      # Change in input shape\n",
        "      # x = ohe_seq.flatten().float()\n",
        "      x = ohe_seq.permute(1,0).float()\n",
        "\n",
        "      y = torch.tensor([label]).float()\n",
        "\n",
        "      return x, y\n",
        "\n",
        "train_dset = CNNDataset(train_df)\n",
        "sample_x, sample_y = train_dset[0]\n",
        "print(sample_x.shape)\n",
        "print(sample_y.shape)"
      ],
      "metadata": {
        "id": "IHdC6pqsAV3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c434f6b-be9b-4733-ef65-203d5ef0d85f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 251])\n",
            "torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(cnn_model, train_dset, epochs=35)"
      ],
      "metadata": {
        "id": "xGgemo9LBi_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4994819-26f4-4f74-9c3e-a26e47b2fc9f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean loss 0.4623096344779205\n",
            "Mean loss 0.3963526786605189\n",
            "Mean loss 0.3641015295084421\n",
            "Mean loss 0.3432862030291642\n",
            "Mean loss 0.33586755254192646\n",
            "Mean loss 0.32506120926233223\n",
            "Mean loss 0.3182017371375136\n",
            "Mean loss 0.3117506699779521\n",
            "Mean loss 0.3094997005504166\n",
            "Mean loss 0.3012959602450536\n",
            "Mean loss 0.29917281947880453\n",
            "Mean loss 0.295575422442649\n",
            "Mean loss 0.29208975065380793\n",
            "Mean loss 0.2874255469145854\n",
            "Mean loss 0.2848425682506567\n",
            "Mean loss 0.28374105215143003\n",
            "Mean loss 0.2788504198052807\n",
            "Mean loss 0.27752759593507054\n",
            "Mean loss 0.2747937791849956\n",
            "Mean loss 0.2735106994297879\n",
            "Mean loss 0.27134237456033194\n",
            "Mean loss 0.2699836543513794\n",
            "Mean loss 0.26868443381054485\n",
            "Mean loss 0.26443246123958225\n",
            "Mean loss 0.263358213975058\n",
            "Mean loss 0.26224901846916787\n",
            "Mean loss 0.2606262507746183\n",
            "Mean loss 0.25921774928270014\n",
            "Mean loss 0.26050435498339225\n",
            "Mean loss 0.25808443061769926\n",
            "Mean loss 0.25756072216043785\n",
            "Mean loss 0.25614851859201365\n",
            "Mean loss 0.2535916131293267\n",
            "Mean loss 0.2537094357488358\n",
            "Mean loss 0.25383398987115346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dset = CNNDataset(test_df)\n",
        "\n",
        "evaluate(cnn_model, train_dset)\n",
        "evaluate(cnn_model, test_dset)"
      ],
      "metadata": {
        "id": "BXU4bdkbCdxf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de35c9aa-37cc-4636-99ba-22ad8e0e8872"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 847/847 [00:07<00:00, 119.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9005424976348877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 283/283 [00:02<00:00, 129.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8536639213562012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solutions"
      ],
      "metadata": {
        "id": "8Cnx3-za46pL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Linear(input_size, hidden_size),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden_size, 1),\n",
        "      nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "GVnzoEwh46W_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=3),\n",
        "        nn.MaxPool1d(kernel_size=3),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3),\n",
        "        nn.MaxPool1d(kernel_size=3),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.LazyLinear(out_features=1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "e9FYfCxP49b0"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}