{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartinekV/DL-for-bio-course/blob/master/02_MNIST_ADVANCED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries setup"
      ],
      "metadata": {
        "id": "f1TIRdTAiT6c"
      }
    },
    {
      "metadata": {
        "id": "PtKvmZx-WmUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ecafcc3-8068-42a9-8ca5-b42e398d76c2"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/519.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/519.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m512.0/519.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation and exploration"
      ],
      "metadata": {
        "id": "oJqJ4hlLiac4"
      }
    },
    {
      "metadata": {
        "id": "lCsBCXMwbpH5"
      },
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_dataset = dsets.MNIST(root = './data', train = True, transform = transforms.ToTensor(), download = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch dataset implements two methods\n",
        "\n",
        "\n",
        "```\n",
        "__len__ #length of the dataset\n",
        "__getitem__ #access to a single datapoint\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "TB7eV_wBinCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.__len__())"
      ],
      "metadata": {
        "id": "6BaDVNb7_zS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = {num:0 for num in range(10)}\n",
        "for x,y in train_dataset:\n",
        "  counts[y]+=1\n",
        "\n",
        "counts"
      ],
      "metadata": {
        "id": "ksy7qbE2Uarp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_index = 1234 #from 0 to 59999\n",
        "sample_X, sample_y = train_dataset.__getitem__(sample_index)"
      ],
      "metadata": {
        "id": "NrvayHlK_626"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_image = transforms.ToPILImage()\n",
        "resize = transforms.Resize((100,100))\n",
        "resize(to_image(sample_X)).show()\n",
        "print(sample_y)\n"
      ],
      "metadata": {
        "id": "RLA659eC-OoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_X"
      ],
      "metadata": {
        "id": "xS2-X6UtBK-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#Check if the data is preprocessed and normalized\n",
        "\n",
        "print('Shape:' ,sample_X.size())\n",
        "print('Std:', torch.std_mean(sample_X))\n",
        "print('Max:', torch.max(sample_X))\n",
        "print('Min:', torch.min(sample_X))"
      ],
      "metadata": {
        "id": "FWh4aeaMBZPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading"
      ],
      "metadata": {
        "id": "cmsAIPMekxSc"
      }
    },
    {
      "metadata": {
        "id": "rfDPBdnYgfGp"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_X, batch_y = next(iter(train_loader))\n",
        "print(batch_X.size())\n",
        "print(batch_y.size())"
      ],
      "metadata": {
        "id": "-VPBPg6cDFez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_y"
      ],
      "metadata": {
        "id": "qnDJJHYFDaGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "4xBBpcUip_mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic regression model"
      ],
      "metadata": {
        "id": "g-1QK42vT_W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "# Using pytorch nn.Module class\n",
        "class LogisticRegressionClassifier(nn.Module):\n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear = nn.Linear(input_size, num_classes)\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear(x)\n",
        "    out = self.softmax(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "IdfVUszmY01Z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "3_tDofQSTukS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    #TODO\n",
        "    pass\n",
        "  def forward(self,x):\n",
        "    #TODO\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "urUq_Yuj0Txn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the MLP\n",
        "# net = MLP(input_size=28*28, hidden_size = 100, num_classes=10)\n",
        "# sample_input = torch.rand(1,784)\n",
        "# net(sample_input).size()"
      ],
      "metadata": {
        "id": "N2BChhYS0PyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "mtmRc4qm5G1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super().__init__()\n",
        "    #TODO\n",
        "    pass\n",
        " \n",
        "  def forward(self,x):\n",
        "    #TODO\n",
        "    pass"
      ],
      "metadata": {
        "id": "SgIg9zKF5FiR"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the MLP\n",
        "# net = CNN(num_classes=10)\n",
        "# sample_input = torch.rand(32,1,28,28)\n",
        "# net(sample_input).size()"
      ],
      "metadata": {
        "id": "TAw2JoRZ6pak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model creation"
      ],
      "metadata": {
        "id": "vc2lCG16T41N"
      }
    },
    {
      "metadata": {
        "id": "-3EPEqbjjfAT"
      },
      "cell_type": "code",
      "source": [
        "# Pixels on input will be spreaded out\n",
        "net = LogisticRegressionClassifier(input_size=28*28, num_classes=10)\n",
        "net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = torch.rand(1, 784)"
      ],
      "metadata": {
        "id": "3siFKMlzmtNQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net(test_input)"
      ],
      "metadata": {
        "id": "gPRAGPgbmrH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_X, batch_y = next(iter(train_loader))\n",
        "net(batch_X).size()"
      ],
      "metadata": {
        "id": "ktO6ndh4XubU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our data shape doesnt match the network input shape\n",
        "batch_X.size()"
      ],
      "metadata": {
        "id": "7aOdzuAvJ5hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_X = batch_X.reshape(-1,28*28)\n",
        "batch_X.size()"
      ],
      "metadata": {
        "id": "HkxPZLtOJ8eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net(batch_X).size()"
      ],
      "metadata": {
        "id": "QvK9JmeoX_xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('number of parameters')\n",
        "print(sum(p.numel() for p in net.parameters() if p.requires_grad))"
      ],
      "metadata": {
        "id": "vam-6DTDDLD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "AkJL3a-jYKNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = LogisticRegressionClassifier(input_size=28*28, num_classes=10)"
      ],
      "metadata": {
        "id": "AOHQOEAjtpQv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ePLIwvAFj2zH"
      },
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import Accuracy\n",
        "\n",
        "accuracy_function = Accuracy(task='multiclass', num_classes=10)"
      ],
      "metadata": {
        "id": "mmDnHzFUoGvD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u75Xa5VckuTH"
      },
      "cell_type": "code",
      "source": [
        "num_epochs=3\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_idx ,(images,labels) in enumerate(train_loader):\n",
        "    images = images.reshape(-1,28*28)\n",
        "    \n",
        "    outputs = net(images)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    if (batch_idx) % 250 == 0:\n",
        "      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Accuracy: %.4f'\n",
        "        %(epoch+1, num_epochs, batch_idx, len(train_loader.dataset)//images.size()[0], loss.item(), accuracy_function(outputs,labels)))\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def get_accuracy(model, loader):\n",
        "  model.eval()\n",
        "  all_predictions = []\n",
        "  all_labels = []\n",
        "  with torch.no_grad(): #Uses less GPU memory and is faster\n",
        "    for images,labels in tqdm(loader):\n",
        "      images = images.reshape(-1,28*28)\n",
        "      labels = labels\n",
        "      \n",
        "      output = model(images)\n",
        "      all_predictions.append(output)\n",
        "      all_labels.append(labels)\n",
        "\n",
        "  #torch.cat concats tensors along new dimension\n",
        "  print('Accuracy:', accuracy_function(torch.cat(all_predictions), torch.cat(all_labels)).item())"
      ],
      "metadata": {
        "id": "O2_CfOTQZCRq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(net, train_loader)"
      ],
      "metadata": {
        "id": "lS8a2rt3Zhyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "beDB4Sx0ujAx"
      }
    },
    {
      "metadata": {
        "id": "DTPvMW5jHB9X",
        "outputId": "cd5420c8-dc95-47ec-896f-07fb4cd52aff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "test_data = dsets.MNIST(root = './data', train = False, transform = transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = 128, shuffle = False)\n",
        "\n",
        "print(test_data.__len__())\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(net, test_loader)"
      ],
      "metadata": {
        "id": "OBQxNJaGavbA",
        "outputId": "44220b44-9ac6-4f85-bec1-7c376e73adce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:01<00:00, 45.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.925000011920929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: Solve the problem with MLP\n",
        "# Exercise: Solve the problem with CNN"
      ],
      "metadata": {
        "id": "b-oBcCFns8yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch lightning"
      ],
      "metadata": {
        "id": "sgEBNV6094bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pytorch-lightning"
      ],
      "metadata": {
        "id": "ehaBKm7R-UsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "class CNN_PL(pl.LightningModule):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(num_classes),\n",
        "            nn.Softmax(dim=-1),\n",
        "        )\n",
        "        self.accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        pred = self(x)\n",
        "        loss = F.cross_entropy(pred, y)\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "\n",
        "        accuracy = self.accuracy(pred, y)\n",
        "        self.log('train_accuracy', accuracy, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        pred = self(x)\n",
        "        metrics = {'accuracy':self.accuracy(pred, y)}\n",
        "        self.log_dict(metrics)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "l15RwgGf-N98"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dsets.MNIST(root = './data', train = True, transform = transforms.ToTensor(), download = True)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = 32, shuffle = True)\n",
        "\n",
        "test_data = dsets.MNIST(root = './data', train = False, transform = transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = 128, shuffle = False)"
      ],
      "metadata": {
        "id": "MBL7D8y5H76t"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN_PL(num_classes=10)\n",
        "\n",
        "# Optional GPU acceleration accelerator='gpu' in Trainer\n",
        "trainer = pl.Trainer(max_epochs=3)\n",
        "trainer.fit(model, train_loader)"
      ],
      "metadata": {
        "id": "apujnsh7IFzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(dataloaders=train_loader)"
      ],
      "metadata": {
        "id": "SF0KDFdJCSZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(dataloaders=test_loader)\n"
      ],
      "metadata": {
        "id": "uxyuU6GzCfhu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}